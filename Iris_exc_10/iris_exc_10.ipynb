{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.datasets import boston_housing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Lambda\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width           class\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_mapping = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n",
    "df['class'] = df['class'].map(species_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[[\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"]]\n",
    "y = to_categorical(df[\"class\"]) # Преобразование меток в формат one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(4,)),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(3, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"acc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4605 - loss: 0.2397  \n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - acc: 0.7038 - loss: 0.1613  \n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6948 - loss: 0.1429 \n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - acc: 0.8540 - loss: 0.1222\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - acc: 0.7502 - loss: 0.1186\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - acc: 0.8780 - loss: 0.1060\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7496 - loss: 0.1082 \n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9390 - loss: 0.0880 \n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9571 - loss: 0.0895 \n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9024 - loss: 0.0819 \n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.8847 - loss: 0.0778 \n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - acc: 0.8836 - loss: 0.0752\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - acc: 0.9479 - loss: 0.0710  \n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154us/step - acc: 0.9736 - loss: 0.0567\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - acc: 0.8919 - loss: 0.0619\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - acc: 0.9250 - loss: 0.0562\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9502 - loss: 0.0590 \n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - acc: 0.8795 - loss: 0.0592\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9831 - loss: 0.0435 \n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9365 - loss: 0.0498 \n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9509 - loss: 0.0416 \n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9642 - loss: 0.0366 \n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - acc: 0.9777 - loss: 0.0314\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - acc: 0.9757 - loss: 0.0342\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9529 - loss: 0.0330 \n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9614 - loss: 0.0325 \n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9643 - loss: 0.0270 \n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9601 - loss: 0.0316 \n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - acc: 0.9727 - loss: 0.0231\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9331 - loss: 0.0335 \n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9594 - loss: 0.0242 \n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - acc: 0.9776 - loss: 0.0293\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9672 - loss: 0.0262 \n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - acc: 0.9204 - loss: 0.0325\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - acc: 0.9702 - loss: 0.0271  \n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9654 - loss: 0.0227 \n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - acc: 0.9866 - loss: 0.0254\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - acc: 0.9694 - loss: 0.0186\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15us/step - acc: 0.9812 - loss: 0.0197\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - acc: 0.9268 - loss: 0.0308\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9835 - loss: 0.0180 \n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9676 - loss: 0.0271 \n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - acc: 0.9549 - loss: 0.0309  \n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - acc: 0.9723 - loss: 0.0247  \n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - acc: 0.9691 - loss: 0.0154  \n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9416 - loss: 0.0294 \n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9644 - loss: 0.0216 \n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9599 - loss: 0.0237 \n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9492 - loss: 0.0251 \n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9866 - loss: 0.0159 \n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9389 - loss: 0.0286 \n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9818 - loss: 0.0152 \n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9849 - loss: 0.0150 \n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9761 - loss: 0.0234 \n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9721 - loss: 0.0181 \n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - acc: 0.9771 - loss: 0.0164\n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - acc: 0.9575 - loss: 0.0201\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9781 - loss: 0.0153 \n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9669 - loss: 0.0198 \n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - acc: 0.9662 - loss: 0.0162\n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9811 - loss: 0.0174 \n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9780 - loss: 0.0156 \n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9812 - loss: 0.0150 \n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9711 - loss: 0.0147 \n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - acc: 0.9728 - loss: 0.0160  \n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181us/step - acc: 0.9582 - loss: 0.0216\n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9515 - loss: 0.0200 \n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9360 - loss: 0.0217 \n",
      "Epoch 69/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - acc: 0.9763 - loss: 0.0143  \n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - acc: 0.9812 - loss: 0.0213\n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - acc: 0.9729 - loss: 0.0173\n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9941 - loss: 0.0135 \n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9379 - loss: 0.0266 \n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9758 - loss: 0.0157 \n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9425 - loss: 0.0210 \n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9781 - loss: 0.0145 \n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9611 - loss: 0.0195 \n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9692 - loss: 0.0196 \n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9743 - loss: 0.0125 \n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9849 - loss: 0.0112 \n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - acc: 0.9754 - loss: 0.0176\n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9676 - loss: 0.0220 \n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9771 - loss: 0.0157 \n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9474 - loss: 0.0243 \n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9530 - loss: 0.0237 \n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9665 - loss: 0.0147     \n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - acc: 0.9345 - loss: 0.0285\n",
      "Epoch 88/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - acc: 0.9653 - loss: 0.0194\n",
      "Epoch 89/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9823 - loss: 0.0116 \n",
      "Epoch 90/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9723 - loss: 0.0197 \n",
      "Epoch 91/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - acc: 0.9928 - loss: 0.0082   \n",
      "Epoch 92/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9578 - loss: 0.0256 \n",
      "Epoch 93/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138us/step - acc: 0.9524 - loss: 0.0194   \n",
      "Epoch 94/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9708 - loss: 0.0213 \n",
      "Epoch 95/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9613 - loss: 0.0183 \n",
      "Epoch 96/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9746 - loss: 0.0155 \n",
      "Epoch 97/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9781 - loss: 0.0155 \n",
      "Epoch 98/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9705 - loss: 0.0127 \n",
      "Epoch 99/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9780 - loss: 0.0144 \n",
      "Epoch 100/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9888 - loss: 0.0099 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x21aaa37c290>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x0000021AAEC287C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - acc: 0.9000 - loss: 0.0365\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test) # Оценка модели на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.98671532e-01, 1.32843922e-03, 7.92660729e-11],\n",
       "       [9.99228120e-01, 7.71931896e-04, 3.49065590e-12],\n",
       "       [2.38598720e-03, 9.96969879e-01, 6.44202461e-04],\n",
       "       [9.93418455e-01, 6.58153230e-03, 1.27387667e-09],\n",
       "       [9.94366944e-01, 5.63298585e-03, 2.11883355e-09],\n",
       "       [8.47692536e-06, 8.87846202e-02, 9.11206901e-01],\n",
       "       [1.93697179e-03, 9.95466709e-01, 2.59634852e-03],\n",
       "       [9.96385694e-01, 3.61432671e-03, 1.89868385e-10],\n",
       "       [9.97322619e-01, 2.67735333e-03, 1.45057383e-10],\n",
       "       [9.98822391e-01, 1.17761490e-03, 1.42801274e-11],\n",
       "       [3.88442959e-06, 3.20837721e-02, 9.67912257e-01],\n",
       "       [2.46856245e-03, 9.91854191e-01, 5.67725766e-03],\n",
       "       [9.61546553e-04, 9.94693100e-01, 4.34530945e-03],\n",
       "       [9.98679578e-01, 1.32035953e-03, 2.13358515e-11],\n",
       "       [9.97665167e-01, 2.33486830e-03, 5.23710242e-11],\n",
       "       [6.38729334e-03, 9.91627455e-01, 1.98525121e-03],\n",
       "       [1.59366537e-04, 6.72353625e-01, 3.27487022e-01],\n",
       "       [2.54569313e-05, 2.29280263e-01, 7.70694256e-01],\n",
       "       [1.94510922e-03, 9.96748209e-01, 1.30671368e-03],\n",
       "       [8.20075059e-07, 3.50865237e-02, 9.64912653e-01],\n",
       "       [3.10614891e-03, 9.90673482e-01, 6.22034585e-03],\n",
       "       [3.56641117e-08, 6.68829074e-03, 9.93311763e-01],\n",
       "       [1.29697623e-03, 9.39278483e-01, 5.94245195e-02],\n",
       "       [9.96978402e-01, 3.02164629e-03, 1.61435698e-10],\n",
       "       [2.45161704e-08, 5.99533832e-03, 9.94004667e-01],\n",
       "       [4.42476477e-03, 9.93984640e-01, 1.59061933e-03],\n",
       "       [9.96581137e-01, 3.41889355e-03, 1.80072568e-10],\n",
       "       [9.97174144e-01, 2.82578589e-03, 1.96244992e-10],\n",
       "       [9.92733240e-01, 7.26675987e-03, 9.81256743e-10],\n",
       "       [4.58244886e-03, 9.78160799e-01, 1.72567219e-02],\n",
       "       [8.37308107e-05, 4.27511185e-01, 5.72405100e-01],\n",
       "       [9.86769557e-01, 1.32304132e-02, 4.85675056e-09],\n",
       "       [9.87890720e-01, 1.21093160e-02, 3.46940321e-09],\n",
       "       [9.87433374e-01, 1.25665981e-02, 4.11212930e-09],\n",
       "       [2.06083036e-03, 9.78546321e-01, 1.93928760e-02],\n",
       "       [9.95504200e-01, 4.49577300e-03, 3.61432911e-10],\n",
       "       [4.54683835e-03, 9.92928207e-01, 2.52494868e-03],\n",
       "       [1.21021651e-06, 8.87434036e-02, 9.11255419e-01],\n",
       "       [9.93601739e-01, 6.39823731e-03, 1.90438287e-09],\n",
       "       [2.41917465e-03, 9.95181620e-01, 2.39922921e-03],\n",
       "       [1.67096971e-06, 1.60027146e-02, 9.83995616e-01],\n",
       "       [9.99247074e-01, 7.52991240e-04, 3.98997545e-12],\n",
       "       [2.95198930e-04, 6.80162072e-01, 3.19542766e-01],\n",
       "       [3.88442959e-06, 3.20837721e-02, 9.67912257e-01],\n",
       "       [2.01264606e-03, 9.93403375e-01, 4.58399951e-03],\n",
       "       [1.29205245e-03, 8.96831751e-01, 1.01876251e-01],\n",
       "       [8.92869957e-06, 7.75294378e-02, 9.22461629e-01],\n",
       "       [1.47857377e-03, 9.42285717e-01, 5.62357642e-02],\n",
       "       [9.96697664e-01, 3.30230570e-03, 1.21995344e-10],\n",
       "       [1.38971703e-02, 9.84220088e-01, 1.88277313e-03],\n",
       "       [4.51422738e-06, 6.42265007e-02, 9.35769022e-01],\n",
       "       [9.95540082e-01, 4.45995387e-03, 4.47377912e-10],\n",
       "       [9.96640682e-01, 3.35930195e-03, 2.78966905e-10],\n",
       "       [4.19964269e-03, 9.90634322e-01, 5.16610034e-03],\n",
       "       [2.70720164e-04, 9.17209089e-01, 8.25202465e-02],\n",
       "       [9.92589951e-01, 7.41004292e-03, 1.34479827e-09],\n",
       "       [1.01308740e-06, 1.12766214e-02, 9.88722324e-01],\n",
       "       [9.95281518e-01, 4.71847458e-03, 4.73834638e-10],\n",
       "       [9.91732836e-01, 8.26711580e-03, 2.29667241e-09],\n",
       "       [5.14676329e-04, 8.08344364e-01, 1.91140935e-01],\n",
       "       [5.79657182e-02, 9.41746116e-01, 2.88200652e-04],\n",
       "       [1.75957530e-06, 4.71241698e-02, 9.52874064e-01],\n",
       "       [4.16958537e-05, 2.30632290e-01, 7.69325972e-01],\n",
       "       [4.75950264e-06, 6.23321645e-02, 9.37663019e-01],\n",
       "       [2.88281655e-07, 2.84972303e-02, 9.71502542e-01],\n",
       "       [2.23128963e-03, 9.74552989e-01, 2.32157428e-02],\n",
       "       [9.88242209e-01, 1.17578423e-02, 1.01328812e-08],\n",
       "       [9.95289326e-01, 4.71062027e-03, 1.73866876e-09],\n",
       "       [7.59072100e-06, 7.18011111e-02, 9.28191245e-01],\n",
       "       [1.09781377e-05, 2.76506960e-01, 7.23482132e-01],\n",
       "       [9.90426362e-01, 9.57361795e-03, 4.33863567e-09],\n",
       "       [9.96623397e-01, 3.37662012e-03, 2.30796202e-10],\n",
       "       [9.92118835e-01, 7.88118318e-03, 4.48317028e-09],\n",
       "       [1.25322375e-04, 5.87310433e-01, 4.12564248e-01],\n",
       "       [1.59464923e-06, 2.46134475e-02, 9.75384951e-01],\n",
       "       [9.94887888e-01, 5.11214137e-03, 1.28589683e-09],\n",
       "       [5.81915083e-06, 1.06174983e-01, 8.93819153e-01],\n",
       "       [1.78238494e-07, 6.08601188e-03, 9.93913710e-01],\n",
       "       [9.95137274e-01, 4.86274483e-03, 9.47024681e-10],\n",
       "       [7.71595398e-04, 9.62823689e-01, 3.64047363e-02],\n",
       "       [6.72650465e-04, 9.81838584e-01, 1.74887795e-02],\n",
       "       [1.77740920e-04, 6.02883577e-01, 3.96938652e-01],\n",
       "       [1.39749807e-03, 9.97858107e-01, 7.44358404e-04],\n",
       "       [7.87047338e-06, 8.25902522e-02, 9.17401850e-01],\n",
       "       [9.97128189e-01, 2.87185796e-03, 1.24832741e-10],\n",
       "       [2.49687328e-05, 3.11609387e-01, 6.88365638e-01],\n",
       "       [2.69245403e-03, 9.91257310e-01, 6.05021277e-03],\n",
       "       [3.63116596e-05, 2.86493242e-01, 7.13470519e-01],\n",
       "       [1.88251082e-02, 9.80964601e-01, 2.10297338e-04],\n",
       "       [3.60368658e-03, 9.72988963e-01, 2.34073475e-02],\n",
       "       [1.20314898e-03, 9.84499812e-01, 1.42969890e-02],\n",
       "       [9.70524788e-01, 2.94751227e-02, 7.72637492e-08],\n",
       "       [1.15073822e-03, 9.95678365e-01, 3.17089725e-03],\n",
       "       [1.22378848e-03, 9.32228506e-01, 6.65477440e-02],\n",
       "       [9.97551978e-01, 2.44806008e-03, 6.84947099e-11],\n",
       "       [4.89181746e-03, 9.91722643e-01, 3.38557316e-03],\n",
       "       [3.15625869e-07, 2.55228076e-02, 9.74476874e-01],\n",
       "       [7.42597331e-06, 1.17774926e-01, 8.82217586e-01],\n",
       "       [9.96620297e-01, 3.37963481e-03, 2.39599174e-10],\n",
       "       [1.70546323e-02, 9.81304824e-01, 1.64054893e-03],\n",
       "       [5.83345354e-07, 1.64095853e-02, 9.83589828e-01],\n",
       "       [3.09765819e-05, 5.46531796e-01, 4.53437299e-01],\n",
       "       [9.92589951e-01, 7.41004292e-03, 1.34479827e-09],\n",
       "       [6.29087026e-07, 1.76599976e-02, 9.82339442e-01],\n",
       "       [9.92092669e-01, 7.90735893e-03, 1.85175442e-09],\n",
       "       [5.92262077e-04, 9.92958307e-01, 6.44943304e-03],\n",
       "       [4.26342098e-07, 3.29072513e-02, 9.67092335e-01],\n",
       "       [2.99112230e-06, 4.68098298e-02, 9.53187227e-01],\n",
       "       [3.23204813e-03, 9.90870416e-01, 5.89749124e-03],\n",
       "       [1.76966714e-05, 1.95466861e-01, 8.04515421e-01],\n",
       "       [5.65263792e-04, 9.59017336e-01, 4.04174216e-02],\n",
       "       [2.41295481e-03, 9.96232450e-01, 1.35455106e-03],\n",
       "       [9.08121001e-06, 4.62451801e-02, 9.53745782e-01],\n",
       "       [5.89943775e-05, 2.49395370e-01, 7.50545681e-01],\n",
       "       [9.93737936e-01, 6.26210868e-03, 3.97731653e-10],\n",
       "       [4.11708979e-03, 9.94711399e-01, 1.17154047e-03],\n",
       "       [2.66555671e-05, 5.55386469e-02, 9.44434583e-01],\n",
       "       [9.99416947e-01, 5.83048852e-04, 1.62183266e-12],\n",
       "       [3.25363409e-03, 9.92791414e-01, 3.95488553e-03],\n",
       "       [7.48703826e-07, 3.38096879e-02, 9.66189504e-01]], dtype=float32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(x_train)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = df[\"class\"].unique()[pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              \n",
       "Iris-versicolor    44\n",
       "Iris-setosa        40\n",
       "Iris-virginica     36\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_names = [list(species_mapping.keys())[i] for i in pred_class]\n",
    "pd.DataFrame(predicted_class_names).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
